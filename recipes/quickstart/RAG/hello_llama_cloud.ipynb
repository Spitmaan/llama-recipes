{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1ea03a-cc69-45b0-80d3-664e48ca6831",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/meta-llama/llama-recipes/blob/main/recipes/use_cases/RAG/HelloLlamaCloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## This demo app shows:\n",
    "* How to run Llama 3 in the cloud hosted on Replicate\n",
    "* How to use LangChain to ask Llama general questions and follow up questions\n",
    "* How to use LangChain to load a recent web page - Hugging Face's [blog post on Llama 3](https://huggingface.co/blog/llama3) - and chat about it. This is the well known RAG (Retrieval Augmented Generation) method to let LLM such as Llama 3 be able to answer questions about the data not publicly available when Llama 3 was trained, or about your own data. RAG is one way to prevent LLM's hallucination\n",
    "\n",
    "**Note** We will be using [Replicate](https://replicate.com/meta/meta-llama-3-8b-instruct) to run the examples here. You will need to first sign in with Replicate with your github account, then create a free API token [here](https://replicate.com/account/api-tokens) that you can use for a while. You can also use other Llama 3 cloud providers such as [Groq](https://console.groq.com/), [Together](https://api.together.xyz/playground/language/meta-llama/Llama-3-8b-hf), or [Anyscale](https://app.endpoints.anyscale.com/playground) - see Section 2 of the Getting to Know Llama [notebook](https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/Getting_to_know_Llama.ipynb) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dde626",
   "metadata": {},
   "source": [
    "Let's start by installing the necessary packages:\n",
    "- sentence-transformers for text embeddings\n",
    "- FAISS gives us database capabilities \n",
    "- LangChai provides necessary RAG tools for this demo"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c608df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:52:09.432307Z",
     "start_time": "2024-07-23T19:51:59.524824Z"
    }
   },
   "source": [
    "!pip install langchain\n",
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install bs4\n",
    "!pip install replicate"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (0.2.11)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (2.0.31)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (3.9.5)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (0.2.23)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (0.2.2)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (0.1.93)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (1.22.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (2.8.2)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain) (8.5.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2024.7.4)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\r\n",
      "Collecting sentence-transformers\r\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (4.37.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (2.2.2)\r\n",
      "Requirement already satisfied: numpy in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (1.22.4)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (1.1.1)\r\n",
      "Requirement already satisfied: scipy in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (0.23.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sentence-transformers) (10.2.0)\r\n",
      "Requirement already satisfied: filelock in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.11)\r\n",
      "Requirement already satisfied: jinja2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.2)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from networkx->torch>=1.11.0->sentence-transformers) (5.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m227.1/227.1 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-3.0.1\r\n",
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp38-cp38-macosx_10_14_x86_64.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from faiss-cpu) (1.22.4)\r\n",
      "Requirement already satisfied: packaging in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from faiss-cpu) (24.1)\r\n",
      "Downloading faiss_cpu-1.8.0.post1-cp38-cp38-macosx_10_14_x86_64.whl (7.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.3/7.3 MB\u001B[0m \u001B[31m23.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.8.0.post1\r\n",
      "Collecting bs4\r\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from bs4) (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.5)\r\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\r\n",
      "Installing collected packages: bs4\r\n",
      "Successfully installed bs4-0.0.2\r\n",
      "Collecting replicate\r\n",
      "  Downloading replicate-0.29.0-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting httpx<1,>=0.21.0 (from replicate)\r\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\r\n",
      "Requirement already satisfied: packaging in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from replicate) (24.1)\r\n",
      "Requirement already satisfied: pydantic>1.10.7 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from replicate) (2.8.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from replicate) (4.9.0)\r\n",
      "Requirement already satisfied: anyio in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx<1,>=0.21.0->replicate) (4.2.0)\r\n",
      "Requirement already satisfied: certifi in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx<1,>=0.21.0->replicate) (2024.7.4)\r\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\r\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: idna in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx<1,>=0.21.0->replicate) (3.4)\r\n",
      "Requirement already satisfied: sniffio in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\r\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\r\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from pydantic>1.10.7->replicate) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from pydantic>1.10.7->replicate) (2.20.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\r\n",
      "Downloading replicate-0.29.0-py3-none-any.whl (42 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.7/42.7 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.6/75.6 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: h11, httpcore, httpx, replicate\r\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 replicate-0.29.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b9c5546a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:55:01.950197Z",
     "start_time": "2024-07-23T19:54:57.834439Z"
    }
   },
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "REPLICATE_API_TOKEN = getpass()\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "3e8870c1",
   "metadata": {},
   "source": [
    "Next we call the Llama 3 8b chat model from Replicate. You can also use Llama 3 70b model by replacing the `model` name with \"meta/meta-llama-3-70b-instruct\"."
   ]
  },
  {
   "cell_type": "code",
   "id": "ad536adb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:55:10.358350Z",
     "start_time": "2024-07-23T19:55:10.044837Z"
    }
   },
   "source": [
    "from langchain_community.llms import Replicate\n",
    "llm = Replicate(\n",
    "    model=\"meta/meta-llama-3-8b-instruct\",\n",
    "    model_kwargs={\"temperature\": 0.0, \"top_p\": 1, \"max_new_tokens\":500}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "fd207c80",
   "metadata": {},
   "source": [
    "With the model set up, you are now ready to ask some questions. Here is an example of the simplest way to ask the model some general questions."
   ]
  },
  {
   "cell_type": "code",
   "id": "493a7148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:55:17.038011Z",
     "start_time": "2024-07-23T19:55:13.462607Z"
    }
   },
   "source": [
    "question = \"who wrote the book Innovator's dilemma?\"\n",
    "answer = llm.invoke(question)\n",
    "print(answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"The Innovator's Dilemma: When New Technologies Cause Great Firms to Fail\" was written by Clayton M. Christensen, a Harvard Business School professor. The book was first published in 1997 and has since become a classic in the field of business and innovation.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f315f000",
   "metadata": {},
   "source": [
    "We will then try to follow up the response with a question asking for more information on the book. \n",
    "\n",
    "Since the chat history is not passed on Llama doesn't have the context and doesn't know this is more about the book thus it treats this as new query.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b5c8676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:55:36.653562Z",
     "start_time": "2024-07-23T19:55:29.390769Z"
    }
   },
   "source": [
    "# chat history not passed so Llama doesn't have the context and doesn't know this is more about the book\n",
    "followup = \"tell me more\"\n",
    "followup_answer = llm.invoke(followup)\n",
    "print(followup_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'd be happy to tell you more about myself.\n",
      "\n",
      "I'm an AI assistant, which means I'm a computer program designed to assist and communicate with humans. My primary goal is to provide helpful and accurate information to answer your questions and complete tasks for you.\n",
      "\n",
      "Here are some things I can do:\n",
      "\n",
      "1. **Answer questions**: I can process natural language queries and provide relevant answers. Whether you're looking for general knowledge, definitions, or specific information, I'm here to help.\n",
      "2. **Generate text**: I can create text based on a prompt or topic. This can be useful for writing articles, emails, or even entire books.\n",
      "3. **Translate languages**: I can translate text from one language to another. I currently support translations in dozens of languages.\n",
      "4. **Summarize content**: If you have a long piece of text and want to get a quick summary of the main points, I can help with that.\n",
      "5. **Offer suggestions**: I can provide suggestions for things like gift ideas, travel destinations, or even just a good book to read.\n",
      "6. **Chat and converse**: I can have a conversation with you, answering your questions and engaging in discussions on a wide range of topics.\n",
      "7. **Help with tasks**: I can assist with tasks like scheduling appointments, sending emails, or even just reminding you of important dates and events.\n",
      "\n",
      "These are just a few examples of what I can do. If you have a specific task or question in mind, feel free to ask me and I'll do my best to help!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "9aeaffc7",
   "metadata": {},
   "source": [
    "To get around this we will need to provide the model with history of the chat. \n",
    "\n",
    "To do this, we will use  [`ConversationBufferMemory`](https://python.langchain.com/docs/modules/memory/types/buffer) to pass the chat history to the model and give it the capability to handle follow up questions."
   ]
  },
  {
   "cell_type": "code",
   "id": "5428ca27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:56:39.270720Z",
     "start_time": "2024-07-23T19:56:39.070196Z"
    }
   },
   "source": [
    "# using ConversationBufferMemory to pass memory (chat history) for follow up questions\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "a3e9af5f",
   "metadata": {},
   "source": [
    "Once this is set up, let us repeat the steps from before and ask the model a simple question.\n",
    "\n",
    "Then we pass the question and answer back into the model for context along with the follow up question."
   ]
  },
  {
   "cell_type": "code",
   "id": "baee2d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:56:52.435295Z",
     "start_time": "2024-07-23T19:56:50.290710Z"
    }
   },
   "source": [
    "# restart from the original question\n",
    "answer = conversation.predict(input=question)\n",
    "print(answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The book \"The Innovator's Dilemma: When New Technologies Cause Great Firms to Fail\" was written by Clayton Christensen, an American academic and business theorist. He's a professor at Harvard Business School and is known for his work on innovation, disruption, and strategy. The book was first published in 1997 and has since become a classic in the field of business and management. It explores the idea that established companies can struggle to innovate and adapt to new technologies, leading to their downfall.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9c7d67a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:58:05.464774Z",
     "start_time": "2024-07-23T19:58:00.777873Z"
    }
   },
   "source": [
    "# pass context (previous question and answer) along with the follow up \"tell me more\" to Llama who now knows more of what\n",
    "memory.save_context({\"input\": question},\n",
    "                    {\"output\": answer})\n",
    "followup_answer = conversation.predict(input=followup)\n",
    "print(followup_answer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'd be happy to tell you more about the book and its author! Clayton Christensen's work is highly regarded in the business and academic communities, and \"The Innovator's Dilemma\" is considered one of his most influential books.\n",
      "\n",
      "In the book, Christensen argues that established companies often struggle to innovate and adapt to new technologies because of their existing business models and organizational structures. He uses the term \"disruptive innovation\" to describe the process by which new technologies or business models disrupt existing markets and industries.\n",
      "\n",
      "Christensen also introduces the concept of the \"innovator's dilemma,\" which refers to the challenge faced by companies that must choose between investing in new technologies or continuing to invest in their existing products and services. He argues that companies that are too focused on their existing products and services may be unable to adapt quickly enough to new technologies, which can lead to their downfall.\n",
      "\n",
      "The book is filled with examples of companies that have struggled to adapt to new technologies, such as the rise of digital photography and the decline of film cameras, or the rise of e-books and the decline of physical books. Christensen also provides case studies of companies that have successfully adapted to new technologies, such as the rise of the personal computer and the decline of the mainframe computer.\n",
      "\n",
      "Overall, \"The Innovator's Dilemma\" is a thought-provoking book that challenges readers to think about the ways in which established companies can struggle to innovate and adapt to new technologies. It's a must-read for anyone interested in business, innovation, and strategy.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "fc436163",
   "metadata": {},
   "source": [
    "Next, let's explore using Llama 3 to answer questions using documents for context. \n",
    "This gives us the ability to update Llama 3's knowledge thus giving it better context without needing to finetune. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:02:35.493486Z",
     "start_time": "2024-07-23T20:02:16.019441Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install unstructured pdf2image pdfminer pdfminer.six ",
   "id": "92e2dadb2305f309",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (0.11.8)\r\n",
      "Requirement already satisfied: pdf2image in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (1.17.0)\r\n",
      "Collecting pdfminer\r\n",
      "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.2/4.2 MB\u001B[0m \u001B[31m23.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: chardet in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (5.2.0)\r\n",
      "Requirement already satisfied: filetype in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (1.2.0)\r\n",
      "Requirement already satisfied: python-magic in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (0.4.27)\r\n",
      "Requirement already satisfied: lxml in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (5.2.2)\r\n",
      "Requirement already satisfied: nltk in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (3.8.1)\r\n",
      "Requirement already satisfied: tabulate in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: requests in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (2.31.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (4.12.2)\r\n",
      "Requirement already satisfied: emoji in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (2.12.1)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (0.6.7)\r\n",
      "Requirement already satisfied: python-iso639 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (2024.4.27)\r\n",
      "Requirement already satisfied: langdetect in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (1.0.9)\r\n",
      "Requirement already satisfied: numpy in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (1.22.4)\r\n",
      "Requirement already satisfied: rapidfuzz in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (3.9.4)\r\n",
      "Requirement already satisfied: backoff in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (2.2.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (4.9.0)\r\n",
      "Requirement already satisfied: unstructured-client in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (0.24.1)\r\n",
      "Requirement already satisfied: wrapt in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: pillow in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from pdf2image) (10.2.0)\r\n",
      "Collecting pycryptodome (from pdfminer)\r\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-macosx_10_9_x86_64.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from beautifulsoup4->unstructured) (2.5)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from dataclasses-json->unstructured) (3.21.3)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from dataclasses-json->unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: six in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from langdetect->unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: click in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from nltk->unstructured) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from nltk->unstructured) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from nltk->unstructured) (2023.10.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from nltk->unstructured) (4.66.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->unstructured) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->unstructured) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->unstructured) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from requests->unstructured) (2024.7.4)\r\n",
      "Requirement already satisfied: deepdiff>=6.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (7.0.1)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (0.27.0)\r\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (1.0.6)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (1.0.0)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (1.6.0)\r\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (24.1)\r\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (4.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (2.8.2)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from unstructured-client->unstructured) (1.0.0)\r\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from deepdiff>=6.0->unstructured-client->unstructured) (4.1.0)\r\n",
      "Requirement already satisfied: anyio in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.2.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.0)\r\n",
      "Downloading pycryptodome-3.20.0-cp35-abi3-macosx_10_9_x86_64.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m26.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: pdfminer\r\n",
      "  Building wheel for pdfminer (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140091 sha256=e61243c2f0a6da26f090277b098005a125bc8d0a459ecea836f4406e227a4789\r\n",
      "  Stored in directory: /Users/mehranspitman/Library/Caches/pip/wheels/1c/28/7d/f390b82bb0307deb63ff27a1474fd308ec68ee028cb9ab6283\r\n",
      "Successfully built pdfminer\r\n",
      "Installing collected packages: pycryptodome, pdfminer\r\n",
      "Successfully installed pdfminer-20191125 pycryptodome-3.20.0\r\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:10:17.343394Z",
     "start_time": "2024-07-23T20:10:15.346674Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install python-docx ",
   "id": "d585c682c8ca05f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\r\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from python-docx) (5.2.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages (from python-docx) (4.9.0)\r\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m244.3/244.3 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: python-docx\r\n",
      "Successfully installed python-docx-1.1.2\r\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:09:58.792602Z",
     "start_time": "2024-07-23T20:09:57.858144Z"
    }
   },
   "cell_type": "code",
   "source": "!pip uninstall -y docx",
   "id": "6ee6507f4a77dda3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: docx 0.2.4\r\n",
      "Uninstalling docx-0.2.4:\r\n",
      "  Successfully uninstalled docx-0.2.4\r\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "f5303d75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:14:57.432514Z",
     "start_time": "2024-07-23T20:14:51.006915Z"
    }
   },
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader, UnstructuredFileLoader, UnstructuredPDFLoader, UnstructuredPowerPointLoader, UnstructuredWordDocumentLoader, UnstructuredURLLoader, UnstructuredHTMLLoader\n",
    "import bs4\n",
    "\n",
    "# loader = WebBaseLoader([\"https://huggingface.co/blog/llama3\"])\n",
    "loader = UnstructuredWordDocumentLoader(\"/Users/mehranspitman/Downloads/Mehran_Spitmann_Resume_CV_07_2024_Extra.docx\")\n",
    "docs = loader.load()\n"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "73b8268e",
   "metadata": {},
   "source": [
    "We need to store our document in a vector store. There are more than 30 vector stores (DBs) supported by LangChain. \n",
    "For this example we will use [FAISS](https://github.com/facebookresearch/faiss), a popular open source vector store by Facebook.\n",
    "For other vector stores especially if you need to store a large amount of data - see [here](https://python.langchain.com/docs/integrations/vectorstores).\n",
    "\n",
    "We will also import the HuggingFaceEmbeddings and RecursiveCharacterTextSplitter to assist in storing the documents."
   ]
  },
  {
   "cell_type": "code",
   "id": "eecb6a34",
   "metadata": {},
   "source": [
    "# Split the document into chunks with a specified chunk size\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Store the document into a vector store with a specific embedding model\n",
    "vectorstore = FAISS.from_documents(all_splits, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "36d4a17c",
   "metadata": {},
   "source": [
    "To store the documents, we will need to split them into chunks using [`RecursiveCharacterTextSplitter`](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter) and create vector representations of these chunks using [`HuggingFaceEmbeddings`](https://www.google.com/search?q=langchain+hugging+face+embeddings&sca_esv=572890011&ei=ARUoZaH4LuumptQP48ah2Ac&oq=langchian+hugg&gs_lp=Egxnd3Mtd2l6LXNlcnAiDmxhbmdjaGlhbiBodWdnKgIIADIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCkjeHlC5Cli5D3ABeAGQAQCYAV6gAb4CqgEBNLgBAcgBAPgBAcICChAAGEcY1gQYsAPiAwQYACBBiAYBkAYI&sclient=gws-wiz-serp) on them before storing them into our vector database. \n",
    "\n",
    "In general, you should use larger chuck sizes for highly structured text such as code and smaller size for less structured text. You may need to experiment with different chunk sizes and overlap values to find out the best numbers.\n",
    "\n",
    "We then use `RetrievalQA` to retrieve the documents from the vector database and give the model more context on Llama 3, thereby increasing its knowledge.\n",
    "\n",
    "For each question, LangChain performs a semantic similarity search of it in the vector db, then passes the search results as the context to Llama to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "id": "00e3f72b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:16:01.214135Z",
     "start_time": "2024-07-23T20:15:56.070928Z"
    }
   },
   "source": [
    "# use LangChain's RetrievalQA, to associate Llama 3 with the loaded documents stored in the vector db\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"Who is Mehran Spitmann?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result['result'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehranspitman/opt/anaconda3/envs/EvalTest_py_3_8/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mehran Spitmann is a Ph.D. holder who has worked as a co-founder and team leader, as well as a doctoral fellow.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "7e63769a",
   "metadata": {},
   "source": [
    "Now, lets bring it all together by incorporating follow up questions.\n",
    "\n",
    "First we ask a follow up questions without giving the model context of the previous conversation. \n",
    "Without this context, the answer we get does not relate to our original question."
   ]
  },
  {
   "cell_type": "code",
   "id": "53f27473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T20:16:41.726472Z",
     "start_time": "2024-07-23T20:16:35.405258Z"
    }
   },
   "source": [
    "# no context passed so Llama 3 doesn't have enough context to answer so it lets its imagination go wild\n",
    "result = qa_chain({\"query\": \"Explain more about him. Give me a brief description of his educational background and work experience.\"})\n",
    "print(result['result'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Based on the provided context, here is a brief description of his educational background and work experience:\n",
      "\n",
      "Educational Background:\n",
      "\n",
      "* Doctoral Fellow at Dartmouth College (2016-2021)\n",
      "* No other educational background mentioned in the provided context\n",
      "\n",
      "Work Experience:\n",
      "\n",
      "* Co-founder & Team Leader, Azdaa Development Team (2007-2010)\n",
      "\t+ Led a team in designing, developing, and maintaining various web and desktop projects\n",
      "\t+ Demonstrated leadership skills by guiding and managing a team of developers\n",
      "* Senior Software Manager, Padisar Informatics Inc. (2014-2015)\n",
      "\t+ Led a software development team in revamping a core E-banking system with a web-based interface\n",
      "\t+ Served as the team leader, providing guidance and direction to the software development team\n",
      "* Doctoral Fellow, Dartmouth College (2016-2021)\n",
      "\t+ Unraveled learning mechanisms in the brain using data science and machine learning\n",
      "\t+ Employed data science and machine learning techniques to understand how the brain's structure influences learning\n",
      "\n",
      "Note that there may be additional information not mentioned in the provided context, but based on what is available, this is a brief summary of his educational background and work experience.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "833221c0",
   "metadata": {},
   "source": [
    "As we did before, let us use the `ConversationalRetrievalChain` package to give the model context of our previous question so we can add follow up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743644a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ConversationalRetrievalChain to pass chat history for follow up questions\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "chat_chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's ask the original question What's new with Llama 3?\" again\n",
    "result = chat_chain({\"question\": question, \"chat_history\": []})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we pass chat history along with the follow up so good things should happen\n",
    "chat_history = [(question, result[\"answer\"])]\n",
    "followup = \"Based on what architecture?\"\n",
    "followup_answer = chat_chain({\"question\": followup, \"chat_history\": chat_history})\n",
    "print(followup_answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d22347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further follow ups can be made possible by updating chat_history like this:\n",
    "chat_history.append((followup, followup_answer[\"answer\"]))\n",
    "more_followup = \"What changes in vocabulary size?\"\n",
    "more_followup_answer = chat_chain({\"question\": more_followup, \"chat_history\": chat_history})\n",
    "print(more_followup_answer['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62daf288-bfca-4853-b153-0d8c73412804",
   "metadata": {},
   "source": [
    "**Note:** If results can get cut off, you can set \"max_new_tokens\" in the Replicate call above to a larger number (like shown below) to avoid the cut off.\n",
    "\n",
    "```python\n",
    "model_kwargs={\"temperature\": 0.01, \"top_p\": 1, \"max_new_tokens\": 1000}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbfbc6-e784-4cc9-8bd8-7f11e16c9456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
